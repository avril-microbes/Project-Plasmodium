---
title: "report8"
output: html_document
---

# Load libraries
```{r}
library(deSolve)
library(splines)
library(optimParallel)
library(ggplot2)
library(ggpubr)
library(tidyr)
library(magrittr)
library(Rcpp)
library(microbenchmark)
library(GA)
library(here)
library(caTools)
```

# Load functions
```{r}
source(here("functions/chabaudi_ci_opt_lag.R"))
source(here("functions/co_infection_opt.R"))
source(here("functions/par_to_df.R"))
source(here("functions/chabaudi_si_opt_lag.R"))
source(here("functions/total_parasite.R"))
source(here("functions/test.R"))
```

# define parameters
```{r}
parameters <- c(R1 = 8.5*10^6,
                lambda = 3.7*10^5,
                mu = 0.025, 
                p = 4*10^-6,
                alpha = 1, 
                alphag = 2, 
                beta = 10, 
                mum = 48, 
                mug = 4, 
                I0 = 43.85965, 
                Ig0 = 0, 
                a = 150, 
                b = 100, 
                sp = 1)

parameters_tsukushi <- c(R1 = 8.89*10^6, # slightly higher
                lambda = 3.7*10^5,
                mu = 0.025, 
                p = 8*10^-6, # doubled form original
                alpha = 1, 
                alphag = 2, 
                beta = 5.721, 
                mum = 48, 
                mug = 4, 
                I0 = 43.85965, 
                Ig0 = 0, 
                a = 150, 
                b = 100, 
                sp = 1,
                psin = 16.69234,
                psiw = 0.8431785,
                phin = 0.03520591, 
                phiw = 550.842,
                iota = 2.18*(10^6),
                rho = 0.2627156,
                mud = -log(1-0.94)) # drug induced action. 94% death per day

time_range <- seq(0, 20, by = 1e-3)
I_range <- seq(0, 2.18*10^6, by = 1000) 
I_range_large <- seq(0, (3.7*10^5)*(8.5*10^6)/((3.7*10^5)-0.025*(8.5*10^6)), by = 1000) 
I_range_mid <- seq(0, 5*10^6, by = 1000)
I_range_mid2 <- seq(0, 4*10^6, by = 1000)
I_range_mid4 <- seq(0, 6*10^6, by = (6*10^6)/5000)

# logged counterpart
I_range_mid2_log <- seq(0, log(4*10^6), by = log(4*10^6)/5000)
I_range_mid3_log <- seq(0, log(5*10^6), by = log(5*10^6)/5000)
I_range_mid4_log <- seq(0, log(6*10^6), by = log(6*10^6)/5000)
I_range_mid4_log10 <- seq(0, log10(6*10^6), by = log10(6*10^6)/5000)
I_range_large_log10 <- seq(0, log10((3.7*10^5)*(8.5*10^6)/((3.7*10^5)-0.025*(8.5*10^6))), by = log10((3.7*10^5)*(8.5*10^6)/((3.7*10^5)-0.025*(8.5*10^6)))/10000)
```


#-----------------------------#
# continue with dual axis optimization
#------------------------------#

# testing gam. Better! 
```{r}
library(mgcv)
# basic set up
cue_range <- seq(0,100,1)
cue_rangeb <- seq(0,1,0.01)
cr_grid <- expand.grid(cue_range, cue_rangeb)
names(cr_grid) <- c("cue_range", "cue_rangeb") # must have the same name!!!
y <- runif(length(cue_rangeb), 0, 1)

df <- data.frame(cue_range,cue_rangeb,y)

# run gam model with tensor product smooth. 3 basis spline for each variable. Tensor product smooth makes more sense for different unit variables.
mod3 <- mgcv::gam(y ~ te(cue_range, cue_rangeb, k = c(3,3)), data = df, method = "REML")
mod32 <- mgcv::gam(y ~ te(cue_range, cue_rangeb, k = c(3,3)), data = df, method = "REML")
mod4 <- mgcv::bam(y ~ te(cue_range, cue_rangeb, k = c(3,3)), data = df, method = "REML")

# assign coefficient. Takes 9!
mod3$coefficients <- rep(0.5, 9)
mod4$coefficients <- rep(0.5, 9)
mod32$coefficients <- rep(-1, 9)

# predict
cr_df3 <- data.frame(pred = mgcv::predict.gam(mod3, newdata = cr_grid), cr_grid)
cr_df32 <- data.frame(pred = mgcv::predict.gam(mod32, newdata = cr_grid), cr_grid)

# plot
ggplot() +
  geom_tile(data = cr_df3, aes(x = cue_range, y = cue_rangeb, fill = pred)) +
  viridis::scale_fill_viridis() +
  theme_bw() +
  theme(legend.position="bottom")
vis.gam(mod3, c("cue_range", "cue_rangeb"), plot.type = "contour")

ggplot() +
  geom_tile(data = cr_df32, aes(x = cue_range, y = cue_rangeb, fill = pred)) +
  viridis::scale_fill_viridis() +
  theme_bw() +
  theme(legend.position="bottom")
vis.gam(mod32, c("cue_range", "cue_rangeb"), plot.type = "contour")

# write function for later
cr <- function(mod, cue_1, cue_2){
  res <- 
mgcv::predict.gam(mod, newdata = data.frame("cue_range"=cue_1,"cue_rangeb"=cue_2))
  return(res)
}

cr2 <- function(mod, cue_1, cue_2){
  res <- predict(mod, newdata = data.frame("cue_range"=cue_1,"cue_rangeb"=cue_2))
  return(res)
}


cr3 <- function(mod, cue_1, cue_2){
  res <- predict(mod, newdata = data.frame("cue_range"=cue_1,"cue_rangeb"=cue_2))
  return(res)
}

cr5 <- function(mod, cue_1, cue_2){
  df <- data.frame("cue_range"=cue_1,"cue_rangeb"=cue_2)
  res <- predict(mod, newdata = df)
  return(res)
}

cr6 <- function(mod, cue_1, cue_2){
  res <- exp(-exp(predict(mod, newdata = data.frame("cue_range"=cue_1,"cue_rangeb"=cue_2))))
  return(res)
}


```

# trying to fasten the function
```{r}
# using mgcv to predict while double exponentiating it
cr_df3 <- data.frame(pred = exp(-exp(mgcv::predict.gam(mod3, newdata = c(1,100)))), cr_grid)
cr(mod3, 0, 0.1)

# alternative approach. Using grid expand then thin plate interplating it
library(fields)
cr_df3 <- data.frame(pred = mgcv::predict.gam(mod3, newdata = cr_grid), cr_grid) # predict whole grid
x = data.matrix(cr_df3 %>% dplyr::select(cue_range, cue_rangeb))
Tps(x = x, Y = cr_df3$pred, df = 3)

# trying akima interpolation
library(akima)
n_interpolation <- 200
x <- cr_df3$cue_range
y <- cr_df3$cue_rangeb
z <- cr_df3$pred
int <- interp(x, y, z, xo=seq(min(x), max(x), length = n_interpolation),
                              yo=seq(min(y), max(y), length = n_interpolation),
                              linear = FALSE, extrap = TRUE)


# match closest one from dataframe?
## finer grid and get nearest result
cue_range <- seq(0,100,0.1)
cue_rangeb <- seq(0,1,0.001)
cr_grid <- expand.grid(cue_range, cue_rangeb)
names(cr_grid) <- c("cue_range", "cue_rangeb") 
cr_df4 <- data.frame(pred = mgcv::predict.gam(mod3, newdata = cr_grid), cr_grid) 

cr4 <- function(cue_1, cue_2){
  nearest_x <- cr_df4$cue_range[which.min(abs(cue_1 - cr_df4$cue_range))]
  nearest_y <- cr_df4$cue_rangeb[which.min(abs(cue_2 - cr_df4$cue_rangeb))]
  res <- cr_df4$pred[cr_df4$cue_range == nearest_x & cr_df4$cue_rangeb == nearest_y]
  return(res)
}

cr4(0,0.1)
cr(mod3, 0, 0.1)
cr2(mod3,0, 0.1)
cr(mod4, 0,0.1)

# bench mark speed
library(microbenchmark)
microbenchmark(cr(mod3, 0, 0.1),
               cr(mod4, 0,0.1))
```

# testing speed
```{r}
cl <- makeCluster(detectCores()); setDefaultCluster(cl = cl)
lag_si_IW_20.opt_tsukushi <- optimParallel(par = rep(0.5, 7),# new parameter search space
                      fn = chabaudi_si_opt_lag2, 
                      control = list(trace = 6, fnscale = -1),
                      immunity = "tsukushi",
                 parameters = parameters_tsukushi,
                 time_range = seq(0, 25, 1e-3),
                 df = 2,
                 cue = "I",
                 cue_b = "W",
                 cue_range = I_range_mid4_log10,
                 cue_range_b = seq(0, log10(5), by = log10(5)/5000),
                 solver = "vode",
                 log_cue = "log10",
                 log_cue_b = "none",
                 dual_cue = TRUE)
stopCluster(cl)

source(here("functions/test.R"))

test <- chabaudi_si_opt_lag2(parameters_cr = rep(0.5, 9),
                             immunity = "tsukushi",
                             parameters = parameters_tsukushi,
                             time_range = seq(0, 25, 1e-3),
                             df = 3,
                             dual_cue = TRUE,
                             cue = "I",
                             cue_b = "W",
                             cue_range = seq(0, log10(6*10^6), by = log10(6*10^6)/5000), 
                             cue_range_b = seq(0, 2, by = 2/5000),
                             solver = "vode",
                             log_cue = "log10", 
                             log_cue_b = "none",
                             dyn = TRUE)


```


#-----------------------#
# Figure 1
# Quantifying state differentiation and noise in a range of cues
#-----------------------#

# get typical infection using optimal co-infection parameters
```{r}
ci_dynamics <- chabaudi_ci_opt_lag(
  parameters_cr_1 = c(360.3151, -470.3701, -325.4047, -371.3250), 
  parameters_cr_2 = c(360.3151, -470.3701, -325.4047, -371.3250), 
  immunity = "tsukushi",
  parameters = parameters_tsukushi,
  time_range = time_range,
  df = 3,
  cue_1 = "I1+I2",
  cue_2 = "I1+I2",
  cue_range_1 = I_range_mid4_log10,
  cue_range_2 = I_range_mid4_log10,
  solver = "vode",
  dyn = TRUE,
  log_cue_1 = "log10",
  log_cue_2 = "log10")

source(here("functions/test_ci.R"))
 # incorporaite burst intestiy
ci_dynamics2 <- chabaudi_ci_opt_lag2(
  parameters_cr_1 = c(360.3151, -470.3701, -325.4047, -371.3250), 
  parameters_cr_2 = c(360.3151, -470.3701, -325.4047, -371.3250), 
  immunity = "tsukushi",
  parameters = parameters_tsukushi,
  time_range = time_range,
  df = 3,
  cue_1 = "I1+I2",
  cue_2 = "I1+I2",
  cue_range_1 = I_range_mid4_log10,
  cue_range_2 = I_range_mid4_log10,
  solver = "vode",
  dyn = TRUE,
  log_cue_1 = "log10",
  log_cue_2 = "log10")
```


# function to parse through this automatically
```{r}
evaluate_cue <- function(cue) {
  
  # process cue list for complex and simple ones
  cue.p <- strsplit(gsub("[^[:alnum:] ]", "", cue), " +")[[1]]
  
  # remove log10 from cue.p
  cue.p <- stringr::str_remove(cue.p, "log10")
  
  # get filtered database
  df <- ci_dynamics2 %>% 
    dplyr::filter(variable_alt %in% cue.p) %>% 
    dplyr::group_by(time) %>% 
    dplyr::summarise(sum_cue = sum(value))
  
  #log transform if cue contains log string
  if(stringr::str_detect(cue, "log10")){
    df$sum_cue <- log10(df$sum_cue+1)
  }
  
  # state differentiation (normalized value)
  ## get max value for noramlzation
  max_cue <- max(df$sum_cue)
  min_cue <- min(df$sum_cue)
  
  ## normalization
  df_norm <- df %>% 
    dplyr::mutate(cue_norm = (sum_cue - min_cue)/(max_cue - min_cue))
  
  ## get average growth value
  df.growth <- df_norm %>% dplyr::filter(time <= 8.581) 
  df.decline <- df_norm %>% dplyr::filter(time >= 8.581)
  
  ## get average growth and decline values
  growth <- mean(df.growth$cue_norm)
  decline <- mean(df.decline$cue_norm)
  growth_decline <- growth-decline
  
  # calculate SNR (smoothed mean / smoothed standard deviation)
  SNR_df <- df %>% 
    dplyr::mutate(cue_mean = runmean(sum_cue, 1000),
                cue_sd = runsd(sum_cue, 1000)) %>% 
    dplyr::mutate(SNR = cue_mean/cue_sd) 
  
  SNR_avg <- mean(SNR_df$SNR[is.finite(SNR_df$SNR)], na.rm = TRUE)
  
  # return interesting values
  res <- c(cue, as.numeric(growth_decline), as.numeric(SNR_avg))
}
```

# basic density-based cues
```{r}
# note: all log10 are log10(cue+1)
cue_basic.ls <- lapply(c("I", "log10(I)", "Ig", "log10(Ig)", "I + Ig", "log10(I + Ig)",
                 "G", "log10(G)",
                 "M", "log10(M)", "Mg", "log10(Mg)", "M + Mg", "log10(M + Mg)",
                 "R", "log10(R)",
                 "W", "BI", "BIg", "BIt"), evaluate_cue) # R and log(R) not used because high SNR


cue_basic.df <- data.frame(do.call(rbind, cue_basic.ls))
names(cue_basic.df) <- c("Cue", "State_differentiation", "SNR")
cue_basic.df$State_differentiation <- as.numeric(cue_basic.df$State_differentiation)
cue_basic.df$SNR <- as.numeric(cue_basic.df$SNR)

# add column to shown R and R in zoom 
cue_basic.df <- cue_basic.df %>% 
  dplyr::mutate(zoom = ifelse(stringr::str_detect(Cue, "R"), FALSE, TRUE)) 

fig1a <- ggplot() +
  geom_point(data = cue_basic.df %>% 
               dplyr::filter(zoom == TRUE), aes(x = State_differentiation, y = SNR, color = Cue)) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = median(cue_basic.df$SNR)) +
  ggrepel::geom_text_repel(data = cue_basic.df %>% 
               dplyr::filter(zoom == TRUE), aes(x = State_differentiation, y = SNR, label = Cue),
                            box.padding = 0.5, max.overlaps = Inf) +
  theme_bw() +
  theme(legend.position = "none")

fig1b <- ggplot() +
  geom_point(data = cue_basic.df, aes(x = State_differentiation, y = SNR, color = Cue)) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = median(cue_basic.df$SNR)) +
  ggrepel::geom_text_repel(data = cue_basic.df %>% 
                             dplyr::filter(stringr::str_detect(Cue, "R")),
                           aes(x = State_differentiation, y = SNR, label = Cue),
                           box.padding = 0.5, max.overlaps = Inf) +
  theme_bw() +
  theme(legend.position = "none")

ggarrange(fig1a, fig1b, ncol = 2, widths = c(2,0.75))
ggsave(here("figures/report8/cue_quadrant.png"), width = 8, height = 6)
```



## reticulocyte density
```{r}
ci_dynamics.long <- ci_dynamics %>% 
  dplyr::select(-variable_alt, -strain) %>% 
  tidyr::pivot_wider(names_from = variable, values_from = value)
 


# checking burst intensirty. Correlate well with targeted immunity
ci_dynamics2 %>% 
  dplyr::filter(variable == "BI" | variable == "W" | variable == "BIg" | variable == "BIt") %>% 
  ggplot() + 
  geom_line(aes(x = time, y = value)) +
  facet_wrap(~variable, scale = "free")
```


#------------------------#
# figure 2
#-----------------------#
```{r}
evaluate_cue2 <- function(cue) {
  
  # process cue list for complex and simple ones
  cue.p <- strsplit(gsub("[^[:alnum:] ]", "", cue), " +")[[1]]
  
  # remove log10 from cue.p
  cue.p <- stringr::str_remove(cue.p, "log10")
  
  # get filtered database
  df <- ci_dynamics2 %>% 
    dplyr::filter(variable_alt %in% cue.p) %>% 
    dplyr::group_by(time) %>% 
    dplyr::summarise(sum_cue = sum(value)) 
  
  #log transform if cue contains log string
  if(stringr::str_detect(cue, "log10")){
    df$sum_cue <- log10(df$sum_cue+1)
  }

  #  added benefit of smoothing
  ## get smoothed cue (from 1 day before)
  smooth_cue <- as.data.frame(dplyr::lag(zoo::rollapplyr(df$sum_cue, 1000, mean, partial = TRUE)))

  names(smooth_cue) <- "smooth_cue"
  
  # state differentiation (normalized value)
  ## get max value for noramlzation
  max_cue <- max(df$sum_cue)
  min_cue <- min(df$sum_cue)
  
  ## normalization
  df_norm <- df %>% 
    dplyr::mutate(cue_norm = (sum_cue - min_cue)/(max_cue - min_cue))
  
  ## get average growth value
  df.growth <- df_norm %>% dplyr::filter(time <= 8.581) 
  df.decline <- df_norm %>% dplyr::filter(time >= 8.581)
  
  ## get average growth and decline values
  growth <- mean(df.growth$cue_norm)
  decline <- mean(df.decline$cue_norm)
  growth_decline <- growth-decline
  
  # future reliability
  ## get lagged cue  and calculate relative change in one day
  df_norm <- df_norm %>% 
    dplyr::mutate(cue_norm_lag = dplyr::lag(cue_norm, 1000),
                  cue_norm_diff = abs(cue_norm - cue_norm_lag))
  ## get average
  lag_diff_avg <- mean(df_norm$cue_norm_diff[is.finite(df_norm$cue_norm_diff)], na.rm = TRUE)
  
  # calculate SNR (smoothed mean / smoothed standard deviation)
  SNR_df <- df %>% 
    dplyr::mutate(cue_mean = runmean(sum_cue, 1000),
                cue_sd = runsd(sum_cue, 1000)) %>% 
    dplyr::mutate(SNR = cue_mean/cue_sd) 
  
  SNR_avg <- mean(SNR_df$SNR[is.finite(SNR_df$SNR)], na.rm = TRUE)
  
  # calculate SNR of smoothed dataset
  SNR_smooth <- smooth_cue %>% 
    dplyr::mutate(cue_mean = runmean(smooth_cue, 1000),
                cue_sd = runsd(smooth_cue, 1000)) %>% 
    dplyr::mutate(SNR = cue_mean/cue_sd) 
  
  SNR_smooth_avg <- mean(SNR_smooth$SNR[is.finite(SNR_smooth$SNR)], na.rm = TRUE)
  
  SNR_diff <- SNR_smooth_avg-SNR_avg
  
  # return interesting values
  res <- c(cue, as.numeric(growth_decline), as.numeric(SNR_avg), as.numeric(SNR_smooth_avg), as.numeric(SNR_diff), as.numeric(lag_diff_avg))
}
```

```{r}
cue_basic.ls2 <- lapply(c("I", "log10(I)", "Ig", "log10(Ig)", "I + Ig", "log10(I + Ig)",
                 "G", "log10(G)",
                 "M", "log10(M)", "Mg", "log10(Mg)", "M + Mg", "log10(M + Mg)",
                 "R", "log10(R)",
                 "W", "BI", "BIg", "BIt"), evaluate_cue2)

cue_basic.df2 <- data.frame(do.call(rbind, cue_basic.ls2))
names(cue_basic.df2) <- c("Cue", "State_differentiation", "SNR", "Smooth_SNR", "SNR_diff","Lag_diff")

cue_basic.df2$State_differentiation <- as.numeric(cue_basic.df2$State_differentiation)
cue_basic.df2$SNR <- as.numeric(cue_basic.df2$SNR)
cue_basic.df2$Smooth_SNR <- as.numeric(cue_basic.df2$Smooth_SNR)
cue_basic.df2$SNR_diff <- as.numeric(cue_basic.df2$SNR_diff)
cue_basic.df2$Lag_diff <- as.numeric(cue_basic.df2$Lag_diff)

fig2a <- ggplot() +
  geom_point(data = cue_basic.df2, aes(x = SNR_diff, y = Lag_diff, color = Cue)) +
  ggrepel::geom_text_repel(data = cue_basic.df2,
                           aes(x = SNR_diff, y = Lag_diff, label = Cue),
                           box.padding = 0.5, max.overlaps = Inf) +
  xlim(-50,150) +
  theme_bw() +
  labs(x = "SNR post-smoothing", y = "Cue deviation post-lag") +
  theme(legend.position = "none")

fig2b <- ggplot() +
  geom_point(data = cue_basic.df2, aes(x = SNR_diff, y = Lag_diff, color = Cue)) +
  ggrepel::geom_text_repel(data = cue_basic.df2 %>% 
                             dplyr::filter(Cue == "log10(R)" | Cue == "R"),
                           aes(x = SNR_diff, y = Lag_diff, label = Cue),
                           box.padding = 0.5, max.overlaps = Inf) +
  theme_bw() +
  labs(x = "SNR post-smoothing", y = "Cue deviation post-lag") +
  theme(legend.position = "none")

ggarrange(fig2a, fig2b, ncol = 2, widths = c(2,0.75))
ggsave(here("figures/report8/SNR_lag_diff.png"), width = 8, height = 6)
```



